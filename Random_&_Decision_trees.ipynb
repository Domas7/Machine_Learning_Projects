{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Random Forest & Decision Tree Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGU057DfgTIL"
      },
      "source": [
        "* This Project contains three datasets, housing_price_test, housing_price_train, and sample_submission\n",
        "\n",
        "* The goal of the project is to predict the price of a house given its attributes.\n",
        "\n",
        "* Going to build a random forest that consists of multiple decision trees from the training data set. Then, apply it on the test set and submit your code to generate predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kut1m20f4zR"
      },
      "source": [
        "Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "AUvifadOf4G-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1460, 81)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>Street</th>\n",
              "      <th>Alley</th>\n",
              "      <th>LotShape</th>\n",
              "      <th>LandContour</th>\n",
              "      <th>Utilities</th>\n",
              "      <th>...</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>PoolQC</th>\n",
              "      <th>Fence</th>\n",
              "      <th>MiscFeature</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>SaleCondition</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>65.0</td>\n",
              "      <td>8450</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>208500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9600</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2007</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>181500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>68.0</td>\n",
              "      <td>11250</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>223500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>70</td>\n",
              "      <td>RL</td>\n",
              "      <td>60.0</td>\n",
              "      <td>9550</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2006</td>\n",
              "      <td>WD</td>\n",
              "      <td>Abnorml</td>\n",
              "      <td>140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>84.0</td>\n",
              "      <td>14260</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>50</td>\n",
              "      <td>RL</td>\n",
              "      <td>85.0</td>\n",
              "      <td>14115</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>MnPrv</td>\n",
              "      <td>Shed</td>\n",
              "      <td>700</td>\n",
              "      <td>10</td>\n",
              "      <td>2009</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>143000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>75.0</td>\n",
              "      <td>10084</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>2007</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>307000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10382</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Shed</td>\n",
              "      <td>350</td>\n",
              "      <td>11</td>\n",
              "      <td>2009</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>50</td>\n",
              "      <td>RM</td>\n",
              "      <td>51.0</td>\n",
              "      <td>6120</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Abnorml</td>\n",
              "      <td>129900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>190</td>\n",
              "      <td>RL</td>\n",
              "      <td>50.0</td>\n",
              "      <td>7420</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>118000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows Ã— 81 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
              "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
              "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
              "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
              "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
              "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
              "5   6          50       RL         85.0    14115   Pave   NaN      IR1   \n",
              "6   7          20       RL         75.0    10084   Pave   NaN      Reg   \n",
              "7   8          60       RL          NaN    10382   Pave   NaN      IR1   \n",
              "8   9          50       RM         51.0     6120   Pave   NaN      Reg   \n",
              "9  10         190       RL         50.0     7420   Pave   NaN      Reg   \n",
              "\n",
              "  LandContour Utilities  ... PoolArea PoolQC  Fence MiscFeature MiscVal  \\\n",
              "0         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
              "1         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
              "2         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
              "3         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
              "4         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
              "5         Lvl    AllPub  ...        0    NaN  MnPrv        Shed     700   \n",
              "6         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
              "7         Lvl    AllPub  ...        0    NaN    NaN        Shed     350   \n",
              "8         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
              "9         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
              "\n",
              "  MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
              "0      2   2008        WD         Normal     208500  \n",
              "1      5   2007        WD         Normal     181500  \n",
              "2      9   2008        WD         Normal     223500  \n",
              "3      2   2006        WD        Abnorml     140000  \n",
              "4     12   2008        WD         Normal     250000  \n",
              "5     10   2009        WD         Normal     143000  \n",
              "6      8   2007        WD         Normal     307000  \n",
              "7     11   2009        WD         Normal     200000  \n",
              "8      4   2008        WD        Abnorml     129900  \n",
              "9      1   2008        WD         Normal     118000  \n",
              "\n",
              "[10 rows x 81 columns]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Loading the dataset\n",
        "df = pd.read_csv('housing_price_train.csv')\n",
        "df_test = pd.read_csv('housing_price_test.csv')\n",
        "df_test_saleprice = pd.read_csv('sample_submission.csv')\n",
        "df_test_saleprice.drop('Id', axis=1, inplace=True)\n",
        "df_test = pd.concat((df_test, df_test_saleprice), axis=1) # This line is used to add the SalePrice column to the test dataset\n",
        "# Printing amount of rows and columns in the dataset\n",
        "print(df.shape)\n",
        "\n",
        "# Printing the first 10 rows of the dataset\n",
        "#Printing all of the columns in the dataset\n",
        "df.head(10)\n",
        "#print(df.head(5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWmPCu5hmAIj"
      },
      "source": [
        "### Cleaning the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "exQbzeH7mM-I"
      },
      "outputs": [],
      "source": [
        "def PreprocessingData(db):\n",
        "    # Showing NULL values for each column in the dataset and their percentage\n",
        "    null_values = db.isnull().sum().sort_values(ascending=False)\n",
        "    null_values = pd.DataFrame(data=null_values, columns=[\"NullValueCount\"]) \n",
        "    missing = null_values[null_values[\"NullValueCount\"] > 0] \n",
        "    print(missing, \"\\n\", missing/len(db)*100)\n",
        "\n",
        "    # Dropping all columns and rows which have null values >= 70%\n",
        "    if missing.empty:\n",
        "        print(\"There is no missing value in the dataset\")\n",
        "    else:\n",
        "        threshold = int(len(db)*0.7) \n",
        "        db.dropna(thresh=threshold, axis=1, inplace=True)\n",
        "        db.dropna(thresh=len(db.columns) * 0.7, axis=0, inplace=True)\n",
        "\n",
        "        for col in list(missing.index):\n",
        "            if col in db.columns:  # Check if the column exists in the DataFrame\n",
        "                if db[col].dtype == 'object': # Categorical\n",
        "                    db[col].fillna(value=db[col].mode()[0], inplace=True) # most frequent value\n",
        "                else: # Numerical\n",
        "                    db[col].fillna(value=db[col].mean(), inplace=True) # avg value\n",
        "            else:\n",
        "                print(f\"Column '{col}' not found in the DataFrame.\")\n",
        "\n",
        "    return db\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Empty DataFrame\n",
            "Columns: [NullValueCount]\n",
            "Index: [] \n",
            " Empty DataFrame\n",
            "Columns: [NullValueCount]\n",
            "Index: []\n",
            "There is no missing value in the dataset\n",
            "Empty DataFrame\n",
            "Columns: [NullValueCount]\n",
            "Index: [] \n",
            " Empty DataFrame\n",
            "Columns: [NullValueCount]\n",
            "Index: []\n",
            "There is no missing value in the dataset\n"
          ]
        }
      ],
      "source": [
        "Data = PreprocessingData(df)\n",
        "Data_test = PreprocessingData(df_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQ8kz_a-mdNx"
      },
      "source": [
        "### Correlations - Shows which feature affects the saleprice the most."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Irh60fo-nVtw"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\petni\\AppData\\Local\\Temp/ipykernel_5404/2245077881.py:1: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
            "  correlation = df[df.columns].corr()[\"SalePrice\"].sort_values()\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "YearRemodAdd    0.507101\n",
              "YearBuilt       0.522897\n",
              "TotRmsAbvGrd    0.533723\n",
              "FullBath        0.560664\n",
              "1stFlrSF        0.605852\n",
              "TotalBsmtSF     0.613581\n",
              "GarageArea      0.623431\n",
              "GarageCars      0.640409\n",
              "GrLivArea       0.708624\n",
              "OverallQual     0.790982\n",
              "SalePrice       1.000000\n",
              "Name: SalePrice, dtype: float64"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "correlation = df[df.columns].corr()[\"SalePrice\"].sort_values() \n",
        "\n",
        "most_correlated = correlation[correlation >= 0.5]  # Adjust the correlation threshold as needed\n",
        "\n",
        "# Removing lowest correlation features\n",
        "dropped = df.drop(correlation[correlation < 0.5].index, axis=1)\n",
        "\n",
        "# Print the filtered dataframe\n",
        "most_correlated\n",
        "#dropped\n",
        "\n",
        "# Print amount of columns and rows in the filtered dataset\n",
        "#print(dropped.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhnNAO-wnXM6"
      },
      "source": [
        "#### Decision Tree\n",
        "#### Building a Decision Tree:\n",
        "A Decision tree consists of nodes connected by edges. A decision tree is typically, a binary tree.\n",
        "\n",
        "1- DecisionNode class used to save some values for each node we do the spliting on it until we reach the leaf node.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "cYNFB7QY-SJK"
      },
      "outputs": [],
      "source": [
        "class DecisionNode():\n",
        "    def __init__(self, feature_idx=None, threshold=None, value=None, true_branch=None, false_branch=None):\n",
        "        self.feature_idx = feature_idx # index of the feature that is used\n",
        "        self.threshold = threshold     # threshold value for feature when making the decision\n",
        "        self.value = value # Average value if the node is a leaf in the tree\n",
        "        self.true_branch = true_branch # the node we go to if decision returns True\n",
        "        self.false_branch = false_branch # the node we go to if decision returns False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYpCv95F-SJK"
      },
      "source": [
        "# Decision Tree Class\n",
        "This Class consists the following functions:\n",
        "<ol>\n",
        "<li> <b>build_tree</b>: used to create the decision tree nodes</li> \n",
        "<li> <b>calc_variance_reduction</b> : measure the impurity by using variance reduction measure (like MSE) </li> \n",
        "the function takes three parameters (parentRec: the records for the target before split,and the left and right records after splitting. This function used to measure the impurity for each node and decide if we will split or not.\n",
        "<li> <b>majority_vote</b>: used to calculate values for the leaf nodes records which equal to the mean of these records.</li> \n",
        "<li><b>split_by_feature</b>: this function take the feature and the threshold and check if the feature is numerical so it split the records into two node (true which is the left edge and false which is the right edge)\n",
        "if the feature is categorical so it split where the values equal to the threshold</li>\n",
        "<li> <b>fit</b>: Used to train the dataset after spliting the data into two part x: features, y: target</li>\n",
        "<li><b>predict_value</b>: used to predict the value for each record, it is a recursive method to find the leaf node that corresponds to prediction\n",
        "<li><b>predict</b>: take all records for the test data and iterate into each record to predit the y(target) value and save the result into a prediction list. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "HSe6v4r1-SJK"
      },
      "outputs": [],
      "source": [
        "class RegressionDecisionTree():\n",
        "    # constructor\n",
        "    def __init__(self, min_VarianceReduction=1e-7, max_depth=5):        \n",
        "        self.root = None # root of this tree\n",
        "        self.min_VarianceReduction = min_VarianceReduction # minimum VarianceReduction to allow splitt\n",
        "        self.max_depth = max_depth\n",
        " \n",
        "\n",
        "    # used to create the decision tree nodes\n",
        "    def build_tree(self, X, y, current_depth=0):\n",
        "        # we will use decision dictionary to save the feature and the threshold we build the tree on \n",
        "        decision = None\n",
        "        # we will use subtrees dictionary to save the feature and the threshold we build the tree on \n",
        "        subtrees = None\n",
        "        largest_variance_Reduction = 0\n",
        "        # add y as last column of X\n",
        "        df = pd.concat((X, y), axis=1)\n",
        "        n_rows, n_features = X.shape\n",
        "        if current_depth <= self.max_depth:\n",
        "            # iterate through every feature\n",
        "            for feature_idx in range(n_features):\n",
        "                # values of that column\n",
        "                feature_values = X.iloc[:, feature_idx]                \n",
        "                unique_values = feature_values.unique()                \n",
        "                for threshold in unique_values:\n",
        "                    X_trueEdge, X_falseEdge = self.split_by_feature(df, feature_idx, threshold)\n",
        "                    if len(X_trueEdge) > 0 and len(X_falseEdge) > 0:\n",
        "                        y_true = X_trueEdge.iloc[:,-1]\n",
        "                        y_false = X_falseEdge.iloc[:,-1]                        \n",
        "                        # Calculate impurity\n",
        "                        VarianceRed = self.Calc_variance_reduction(y, y_true, y_false)\n",
        "                        # Keep track of which feature gave the largest information gain\n",
        "                        if VarianceRed > largest_variance_Reduction:\n",
        "                            largest_variance_Reduction = VarianceRed\n",
        "                            decision = {\"feature_idx\":feature_idx, \"threshold\":threshold}\n",
        "                            subtrees = {\"X_true\":X_trueEdge.iloc[:,:-1],\n",
        "                                        \"y_true\":y_true,\n",
        "                                        \"X_false\":X_falseEdge.iloc[:,:-1],\n",
        "                                        \"y_false\":y_false}\n",
        "\n",
        "        # we will construct new branch of tree if the variance_Reduction is larger than minimum variance_Reduction that we've defined\n",
        "        if largest_variance_Reduction > self.min_VarianceReduction:\n",
        "            true_branch = self.build_tree(subtrees[\"X_true\"], subtrees[\"y_true\"], current_depth+1)\n",
        "            false_branch = self.build_tree(subtrees[\"X_false\"], subtrees[\"y_false\"], current_depth+1)\n",
        "            return DecisionNode(feature_idx=decision[\"feature_idx\"], threshold=decision[\"threshold\"], true_branch=true_branch, false_branch=false_branch)\n",
        "\n",
        "        # at leaf node we calculate the mean for the records\n",
        "        leaf_value = self.majority_vote(y)\n",
        "        return DecisionNode(value=leaf_value)\n",
        "                        \n",
        "    # measure the impurity by using variance reduction measure (like MSE)\n",
        "    # left_edgeRec= True edge: where condition is true\n",
        "    # Right_edgeRec= False edge: where condition is false\n",
        "    def Calc_variance_reduction(self, parentRec, left_edgeRec, Right_edgeRec):  \n",
        "\n",
        "        parent_variance = np.var(parentRec) # np.var is used to calculate the variance of the parent node, which is the same as entropy for the parent node\n",
        "        p = len(left_edgeRec) / len(parentRec) # weight of the left edge\n",
        "        VarReduction = parent_variance - (p * np.var(left_edgeRec) + (1 - p) * np.var(Right_edgeRec))\n",
        "\n",
        "        # return the VarReduction = variance for parent - (Weight * var(leftEdge) + Weight * var(RightEdge)   \n",
        "        return VarReduction\n",
        "        \n",
        "    \n",
        "    def majority_vote(self, Y): \n",
        "        return round(np.mean(Y), 2)\n",
        "        # return the majority_vote for the leaf nodes  \n",
        "\n",
        "    def split_by_feature(self, X, feature_idx, threshold): # \n",
        "        \n",
        "        if isinstance(threshold, int) or isinstance(threshold, float): #\n",
        "            X_true = X[X.iloc[:, feature_idx] >= threshold] \n",
        "            X_false = X[X.iloc[:, feature_idx] < threshold] \n",
        "        # if the feature is categorical\n",
        "        else:\n",
        "            X_true = X[X.iloc[:, feature_idx] == threshold] \n",
        "            X_false = X[X.iloc[:, feature_idx] != threshold]\n",
        "        \n",
        "        return X_true, X_false\n",
        "\n",
        "        # split the data into left_edge & right_edge depends one specified feature and the threshold\n",
        "        # return left & right edges\n",
        "\n",
        "    # Used to train the dataset after spliting the data into x: features, y: target\n",
        "    def fit(self, X, y):\n",
        "        self.root = self.build_tree(X, y)\n",
        "        #return self.root\n",
        "\n",
        "\n",
        "    def predict_value(self, x_test, tree=None):\n",
        "        if tree is None:\n",
        "            tree = self.root\n",
        "\n",
        "        if tree.value is not None:\n",
        "            return tree.value\n",
        "\n",
        "        feature_value = x_test[tree.feature_idx]\n",
        "        branch = tree.false_branch\n",
        "\n",
        "        if isinstance(feature_value, int) or isinstance(feature_value, float):\n",
        "            if feature_value >= tree.threshold:\n",
        "                branch = tree.true_branch\n",
        "        elif feature_value == tree.threshold:\n",
        "            branch = tree.true_branch\n",
        "\n",
        "        return self.predict_value(x_test, branch)\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        y_pred = []\n",
        "\n",
        "        for idx, row in X_test.iterrows(): \n",
        "            y_pred.append(self.predict_value(row.values)) \n",
        "\n",
        "        return y_pred\n",
        "        \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9aqjovq-SJM"
      },
      "source": [
        "- To Check the Accuracy for our prediction we use CalcAccuracy function which take the actual values for the test dataset and the predicted values and apply the RMSE formula."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "24p2WfE8-SJN"
      },
      "outputs": [],
      "source": [
        "def CalcAccuracy(Actual_Y, Predicted_y): # Calculate the accuracy of the model using RMSE which gives us the error \n",
        "    # Calculate the accuracy of the model using RMSE\n",
        "    rmse_model = np.sqrt(np.mean((Actual_Y - Predicted_y) ** 2))\n",
        "    return rmse_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "7dJKxolT-SJN"
      },
      "outputs": [],
      "source": [
        "x_train = df.iloc[:, :-1]\n",
        "y_train = df.iloc[:, -1]\n",
        "\n",
        "tree = RegressionDecisionTree()\n",
        "tree.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "86417.71870902876"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_test = df_test.iloc[:, :-1]\n",
        "y_test = df_test.iloc[:, -1]\n",
        "predicted_y = tree.predict(x_test)\n",
        "predicted_y \n",
        "\n",
        "#actual_y = pd.to_numeric(y_test, errors='coerce')\n",
        "#predicted_y = pd.to_numeric(predicted_y, errors='coerce')\n",
        "# Calculate the accuracy of the model using RMSE\n",
        "#accuracy = CalcAccuracy(y_test, predicted_y)\n",
        "CalcAccuracy(y_test, predicted_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvzaxcPAoJsk"
      },
      "source": [
        "Random Forest\n",
        "#### Random forest class\n",
        "- the Class consist of the following functions:\n",
        "<ul>\n",
        "    <li>Constructor </li>    \n",
        "    <li>Subsampling </li>\n",
        "    <li>build_model</li>\n",
        "    <li>predict </li>\n",
        "\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "a00zi12Q-SJO"
      },
      "outputs": [],
      "source": [
        "class RF(object):\n",
        "    def __init__(self):\n",
        "        self.Traindata = None  # training data set (loaded into memory)\n",
        "        self.Testdata = None  # Test data set for prediction        \n",
        "        self.trees = []  # list of decision trees \n",
        "          \n",
        "\n",
        "     # This function generate a subsample with replacement\n",
        "    def __subsampling(self, train_set, sample_size_ratio):       \n",
        "        sample_number = round(len(train_set) * sample_size_ratio)\n",
        "        return train_set.sample(n = sample_number, replace=True) #sample_number is the number of rows to return\n",
        "        \n",
        "        \n",
        "    def build_model(self, train_set, sample_size_ratio, number_of_trees):\n",
        "        for i in range(number_of_trees):\n",
        "            TrainingSample = self.__subsampling(train_set, sample_size_ratio) \n",
        "            featurespart = TrainingSample.iloc[:, :-1]\n",
        "            targetpart = TrainingSample.iloc[:, -1]\n",
        "            tree = RegressionDecisionTree()\n",
        "            tree.fit(featurespart, targetpart)\n",
        "            self.trees.append(tree)\n",
        "\n",
        "            \n",
        "               \n",
        "    def predict(self, test_set):\n",
        "        # Predict for each instance in the test set\n",
        "        predictions = []\n",
        "        for idx, row in test_set.iterrows():\n",
        "            instance_prediction = []\n",
        "            for tree in self.trees:\n",
        "                instance_prediction.append(tree.predict_value(row))\n",
        "            predictions.append(np.mean(instance_prediction))\n",
        "        return predictions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITGUmaXc-SJO"
      },
      "source": [
        "### Create Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "SjqaGyyl-qoY"
      },
      "outputs": [],
      "source": [
        "# Instantiate Random Forest\n",
        "train_data_set = df\n",
        "test_data_set = df_test\n",
        "random_forest = RF()\n",
        "#Create Decision Trees\n",
        "\n",
        "build_model = random_forest.build_model(train_data_set, sample_size_ratio=0.8, number_of_trees=5) \n",
        "\n",
        "#Use the random forest to predict the test dataset\n",
        "#predictions = random_forest.predict(test_data_set)\n",
        "#print(predictions)\n",
        "\n",
        "\n",
        "# Assuming train_data and test_data are your training and test datasets respectively\n",
        "# Train the random forest with the dataset\n",
        "#random_forest.build_model(train_data, sample_size_ratio=0.8, number_of_trees=10)\n",
        "\n",
        "# Use the random forest to predict the test dataset\n",
        "#predictions = random_forest.predict(test_data)\n",
        "#print(predictions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "sWmfgEVp-SJO"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "58739.12989257164"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predict = random_forest.predict(test_data_set)\n",
        "predict\n",
        "#Calculating Accuracy\n",
        "CalcAccuracy(y_test, predict)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "vscode": {
      "interpreter": {
        "hash": "e42f74ecac23521ece3572bae462a7c7939cd558a6fbb59afafe09d03193ca58"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
